{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series classification\n",
    "Implementation of Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline (2016, arXiv) in PyTorch by using a skorch wrapper \n",
    "In this script, we are using two datasets originally used in the paper\n",
    "\n",
    "Error while fitting\n",
    "Authors: Marina Georgati, Hao Miao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beef' 'Adiac']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Beef:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory1: c:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\n",
      "Current working directory1: c:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Adiac:  50%|█████     | 1/2 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory1: c:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\n",
      "Current working directory1: c:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Adiac: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import our modules\n",
    "from src import model, utils\n",
    "# Import SKORCH NN classifier\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "datasets = np.loadtxt('src/datasets.txt', dtype=str)\n",
    "print(datasets)\n",
    "#utils.download_datasets(datasets)  # uncomment this to download the data\n",
    "dataset_dictionary = utils.data_dictionary(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 470)\n",
      "(30, 470)\n",
      "470 5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (128x470x1). Calculated output size: (128x235x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\\trial01.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial01.ipynb#ch0000002?line=18'>19</a>\u001b[0m y_test \u001b[39m=\u001b[39m dataloader[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39my\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial01.ipynb#ch0000002?line=19'>20</a>\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial01.ipynb#ch0000002?line=21'>22</a>\u001b[0m nn\u001b[39m.\u001b[39;49mfit(dataloader[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mx, y_test)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\classifier.py:141\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=129'>130</a>\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=130'>131</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=131'>132</a>\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=135'>136</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=136'>137</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=137'>138</a>\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=138'>139</a>\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=139'>140</a>\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1215\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1211'>1212</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1212'>1213</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1214'>1215</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1215'>1216</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1174\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1171'>1172</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1172'>1173</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1173'>1174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1174'>1175</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1175'>1176</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1087\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1083'>1084</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1084'>1085</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_epoch_begin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1086'>1087</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single_epoch(dataset_train, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1087'>1088</a>\u001b[0m                           step_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1089'>1090</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(dataset_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1090'>1091</a>\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1092'>1093</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1122\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[1;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1119'>1120</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(dataset, training\u001b[39m=\u001b[39mtraining):\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1120'>1121</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_batch_begin\u001b[39m\u001b[39m\"\u001b[39m, batch\u001b[39m=\u001b[39mbatch, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1121'>1122</a>\u001b[0m     step \u001b[39m=\u001b[39m step_fn(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1122'>1123</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mrecord_batch(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, step[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1123'>1124</a>\u001b[0m     batch_size \u001b[39m=\u001b[39m (get_len(batch[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1124'>1125</a>\u001b[0m                   \u001b[39melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1007\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=999'>1000</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1000'>1001</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1001'>1002</a>\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1002'>1003</a>\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1003'>1004</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1004'>1005</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m step[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1006'>1007</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_optimizer(step_fn)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1007'>1008</a>\u001b[0m \u001b[39mreturn\u001b[39;00m step_accumulator\u001b[39m.\u001b[39mget_step()\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:963\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[1;34m(self, step_fn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=960'>961</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=962'>963</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(step_fn)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=27'>28</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\optim\\sgd.py:113\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=111'>112</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=112'>113</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=114'>115</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=115'>116</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:997\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=994'>995</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_fn\u001b[39m():\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=995'>996</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_optimizer()\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=996'>997</a>\u001b[0m     step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step_single(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=997'>998</a>\u001b[0m     step_accumulator\u001b[39m.\u001b[39mstore_step(step)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=999'>1000</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1000'>1001</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1001'>1002</a>\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1002'>1003</a>\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1003'>1004</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:896\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=893'>894</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=894'>895</a>\u001b[0m Xi, yi \u001b[39m=\u001b[39m unpack_data(batch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=895'>896</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(Xi, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=896'>897</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loss(y_pred, yi, X\u001b[39m=\u001b[39mXi, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=897'>898</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1359\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[1;34m(self, x, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1356'>1357</a>\u001b[0m     x_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1357'>1358</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx_dict)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1358'>1359</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\\src\\model.py:38\u001b[0m, in \u001b[0;36m_ConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=37'>38</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mavg_pool2d(x,\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=38'>39</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(x,dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=39'>40</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m128\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (128x470x1). Calculated output size: (128x235x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "for dataset, dataloader in dataset_dictionary.items():\n",
    "    print(dataloader['train'].dataset.x.shape)\n",
    "    print(dataloader['test'].dataset.x.shape)\n",
    "    \n",
    "    time_steps = dataloader['test'].dataset.x.shape[-1]\n",
    "    n_classes  = len(np.unique(dataloader['test'].dataset.y))\n",
    "    print(time_steps, n_classes)\n",
    "\n",
    "    # The Neural Net is initialized with fixed hyperparameters\n",
    "    nn = NeuralNetClassifier(\n",
    "        model._ConvNet(time_steps, n_classes), \n",
    "        max_epochs=10, \n",
    "        lr=0.01, \n",
    "        batch_size=12, \n",
    "        optimizer=torch.optim.SGD,\n",
    "        # Shuffle training data on each epoch\n",
    "        iterator_train__shuffle=False )\n",
    "\n",
    "    y_test = dataloader['test'].dataset.y\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    nn.fit(dataloader['train'].dataset.x, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d4520545ca233a18fcbfaf6de76cf00aab1835d3dba167ce44a459e1af2c853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

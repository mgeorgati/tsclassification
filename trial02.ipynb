{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series classification\n",
    "Implementation of Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline (2016, arXiv) in PyTorch by using a skorch wrapper \n",
    "\n",
    "In this notebook, we are using the dataset using during the IML lectures (https://github.com/IBM/sail/tree/imla_notebooks/notebooks/datasets)\n",
    "\n",
    "Error while fitting: RuntimeError: expected scalar type Double but found Float\n",
    "\n",
    "Authors: Marina Georgati, Hao Miao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import our modules\n",
    "from src import data, model, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>commission</th>\n",
       "      <th>age</th>\n",
       "      <th>education level</th>\n",
       "      <th>make of car</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>house value</th>\n",
       "      <th>years house owned</th>\n",
       "      <th>loan</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68757.426754</td>\n",
       "      <td>58022.846494</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>221792.307247</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27402.870141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126298.059683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>248027.000114</td>\n",
       "      <td>6.0</td>\n",
       "      <td>197321.294347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20642.840226</td>\n",
       "      <td>65253.012270</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>591488.097260</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36810.494158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74382.160911</td>\n",
       "      <td>67141.427442</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>123653.321624</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354680.807306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44492.145159</td>\n",
       "      <td>83925.141993</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>204227.660125</td>\n",
       "      <td>11.0</td>\n",
       "      <td>360978.690701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          salary    commission   age  education level  make of car  zipcode  \\\n",
       "0   68757.426754  58022.846494  21.0              4.0          5.0      7.0   \n",
       "1  126298.059683      0.000000  60.0              0.0         19.0      5.0   \n",
       "2   20642.840226  65253.012270  30.0              2.0          5.0      2.0   \n",
       "3   74382.160911  67141.427442  60.0              4.0          2.0      8.0   \n",
       "4   44492.145159  83925.141993  33.0              0.0          2.0      7.0   \n",
       "\n",
       "     house value  years house owned           loan  y  \n",
       "0  221792.307247               10.0   27402.870141  0  \n",
       "1  248027.000114                6.0  197321.294347  0  \n",
       "2  591488.097260               17.0   36810.494158  0  \n",
       "3  123653.321624                4.0  354680.807306  0  \n",
       "4  204227.660125               11.0  360978.690701  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset from https://github.com/AlexImb/automl-streams/blob/master/demos/_datasets/agrawal_gen.csv\n",
    "csv_file = \"C:/Users/NM12LQ/OneDrive - Aalborg Universitet/PhD/PhDCourses/11. IMLA/tsc/data/agrawal_gen_abrupt.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file,\n",
    "                    names=[\"salary\", \"commission\", \"age\", \"education level\", \"make of car\", \"zipcode\", \"house value\", \"years house owned\", \"loan\", \"y\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68757.426754</td>\n",
       "      <td>58022.846494</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>221792.307247</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27402.870141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126298.059683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>248027.000114</td>\n",
       "      <td>6.0</td>\n",
       "      <td>197321.294347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20642.840226</td>\n",
       "      <td>65253.012270</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>591488.097260</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36810.494158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74382.160911</td>\n",
       "      <td>67141.427442</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>123653.321624</td>\n",
       "      <td>4.0</td>\n",
       "      <td>354680.807306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44492.145159</td>\n",
       "      <td>83925.141993</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>204227.660125</td>\n",
       "      <td>11.0</td>\n",
       "      <td>360978.690701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0            x1    x2   x3    x4   x5             x6    x7  \\\n",
       "0   68757.426754  58022.846494  21.0  4.0   5.0  7.0  221792.307247  10.0   \n",
       "1  126298.059683      0.000000  60.0  0.0  19.0  5.0  248027.000114   6.0   \n",
       "2   20642.840226  65253.012270  30.0  2.0   5.0  2.0  591488.097260  17.0   \n",
       "3   74382.160911  67141.427442  60.0  4.0   2.0  8.0  123653.321624   4.0   \n",
       "4   44492.145159  83925.141993  33.0  0.0   2.0  7.0  204227.660125  11.0   \n",
       "\n",
       "              x8  y  \n",
       "0   27402.870141  0  \n",
       "1  197321.294347  0  \n",
       "2   36810.494158  0  \n",
       "3  354680.807306  0  \n",
       "4  360978.690701  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file,\n",
    "                    names=[\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"y\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.431300</td>\n",
       "      <td>1.374318</td>\n",
       "      <td>-1.636464</td>\n",
       "      <td>1.429498</td>\n",
       "      <td>-0.785628</td>\n",
       "      <td>1.158028</td>\n",
       "      <td>-0.914743</td>\n",
       "      <td>-0.644421</td>\n",
       "      <td>-1.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.099179</td>\n",
       "      <td>-0.737589</td>\n",
       "      <td>0.584606</td>\n",
       "      <td>-1.401639</td>\n",
       "      <td>1.643154</td>\n",
       "      <td>0.388963</td>\n",
       "      <td>-0.829445</td>\n",
       "      <td>-1.109183</td>\n",
       "      <td>-0.380831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.711064</td>\n",
       "      <td>1.637480</td>\n",
       "      <td>-1.123909</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>-0.785628</td>\n",
       "      <td>-0.764636</td>\n",
       "      <td>0.287262</td>\n",
       "      <td>0.168913</td>\n",
       "      <td>-1.490517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.281692</td>\n",
       "      <td>1.706214</td>\n",
       "      <td>0.584606</td>\n",
       "      <td>1.429498</td>\n",
       "      <td>-1.306081</td>\n",
       "      <td>1.542561</td>\n",
       "      <td>-1.233826</td>\n",
       "      <td>-1.341564</td>\n",
       "      <td>0.707068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.076714</td>\n",
       "      <td>2.317105</td>\n",
       "      <td>-0.953058</td>\n",
       "      <td>-1.401639</td>\n",
       "      <td>-1.306081</td>\n",
       "      <td>1.158028</td>\n",
       "      <td>-0.971851</td>\n",
       "      <td>-0.528230</td>\n",
       "      <td>0.750608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.423851</td>\n",
       "      <td>-0.737589</td>\n",
       "      <td>0.242903</td>\n",
       "      <td>-0.693855</td>\n",
       "      <td>0.428763</td>\n",
       "      <td>-1.533701</td>\n",
       "      <td>2.318492</td>\n",
       "      <td>-1.225373</td>\n",
       "      <td>-1.398224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>-1.639362</td>\n",
       "      <td>0.573827</td>\n",
       "      <td>-0.668305</td>\n",
       "      <td>-0.693855</td>\n",
       "      <td>-1.306081</td>\n",
       "      <td>-1.533701</td>\n",
       "      <td>1.816275</td>\n",
       "      <td>0.866056</td>\n",
       "      <td>-0.776598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.571919</td>\n",
       "      <td>-0.737589</td>\n",
       "      <td>-1.123909</td>\n",
       "      <td>-0.693855</td>\n",
       "      <td>-1.132597</td>\n",
       "      <td>-1.149168</td>\n",
       "      <td>1.672108</td>\n",
       "      <td>1.330819</td>\n",
       "      <td>1.664225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.703634</td>\n",
       "      <td>-0.737589</td>\n",
       "      <td>0.584606</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.775732</td>\n",
       "      <td>1.542561</td>\n",
       "      <td>-1.424730</td>\n",
       "      <td>-0.179658</td>\n",
       "      <td>-1.073691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>-1.311245</td>\n",
       "      <td>0.174397</td>\n",
       "      <td>-1.294761</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.602248</td>\n",
       "      <td>-1.533701</td>\n",
       "      <td>0.287843</td>\n",
       "      <td>-0.179658</td>\n",
       "      <td>0.209187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0     -0.431300  1.374318 -1.636464  1.429498 -0.785628  1.158028 -0.914743   \n",
       "1      1.099179 -0.737589  0.584606 -1.401639  1.643154  0.388963 -0.829445   \n",
       "2     -1.711064  1.637480 -1.123909  0.013929 -0.785628 -0.764636  0.287262   \n",
       "3     -0.281692  1.706214  0.584606  1.429498 -1.306081  1.542561 -1.233826   \n",
       "4     -1.076714  2.317105 -0.953058 -1.401639 -1.306081  1.158028 -0.971851   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995  0.423851 -0.737589  0.242903 -0.693855  0.428763 -1.533701  2.318492   \n",
       "24996 -1.639362  0.573827 -0.668305 -0.693855 -1.306081 -1.533701  1.816275   \n",
       "24997  0.571919 -0.737589 -1.123909 -0.693855 -1.132597 -1.149168  1.672108   \n",
       "24998  0.703634 -0.737589  0.584606  0.013929  0.775732  1.542561 -1.424730   \n",
       "24999 -1.311245  0.174397 -1.294761  0.013929  0.602248 -1.533701  0.287843   \n",
       "\n",
       "             x7        x8  \n",
       "0     -0.644421 -1.555556  \n",
       "1     -1.109183 -0.380831  \n",
       "2      0.168913 -1.490517  \n",
       "3     -1.341564  0.707068  \n",
       "4     -0.528230  0.750608  \n",
       "...         ...       ...  \n",
       "24995 -1.225373 -1.398224  \n",
       "24996  0.866056 -0.776598  \n",
       "24997  1.330819  1.664225  \n",
       "24998 -0.179658 -1.073691  \n",
       "24999 -0.179658  0.209187  \n",
       "\n",
       "[25000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = df.copy()\n",
    "X.drop(\"y\", axis=1, inplace=True)\n",
    "X[X.columns] = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 9) (25000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning and preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.copy()\n",
    "y = X['y'].values\n",
    "X.drop(\"y\", axis=1, inplace=True)\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "y = y.reshape(len(y),1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 2\n"
     ]
    }
   ],
   "source": [
    "time_steps = X_test.shape[-1]\n",
    "n_classes = len(np.unique(y_test))\n",
    "print(time_steps, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\\trial.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial.ipynb#ch0000008?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial.ipynb#ch0000008?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(y_train\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/trial.ipynb#ch0000008?line=12'>13</a>\u001b[0m nn\u001b[39m.\u001b[39;49mfit(X, y_train)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\classifier.py:141\u001b[0m, in \u001b[0;36mNeuralNetClassifier.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=129'>130</a>\u001b[0m \u001b[39m\"\"\"See ``NeuralNet.fit``.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=130'>131</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=131'>132</a>\u001b[0m \u001b[39mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=135'>136</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=136'>137</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=137'>138</a>\u001b[0m \u001b[39m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=138'>139</a>\u001b[0m \u001b[39m# this is actually a pylint bug:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=139'>140</a>\u001b[0m \u001b[39m# https://github.com/PyCQA/pylint/issues/1085\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/classifier.py?line=140'>141</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(NeuralNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1215\u001b[0m, in \u001b[0;36mNeuralNet.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1211'>1212</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized_:\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1212'>1213</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1214'>1215</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1215'>1216</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1174\u001b[0m, in \u001b[0;36mNeuralNet.partial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1171'>1172</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1172'>1173</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1173'>1174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1174'>1175</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1175'>1176</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1087\u001b[0m, in \u001b[0;36mNeuralNet.fit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1083'>1084</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1084'>1085</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m'\u001b[39m\u001b[39mon_epoch_begin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1086'>1087</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single_epoch(dataset_train, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1087'>1088</a>\u001b[0m                           step_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1089'>1090</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single_epoch(dataset_valid, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1090'>1091</a>\u001b[0m                           step_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_step, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1092'>1093</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_epoch_end\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mon_epoch_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1122\u001b[0m, in \u001b[0;36mNeuralNet.run_single_epoch\u001b[1;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1119'>1120</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(dataset, training\u001b[39m=\u001b[39mtraining):\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1120'>1121</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\u001b[39m\"\u001b[39m\u001b[39mon_batch_begin\u001b[39m\u001b[39m\"\u001b[39m, batch\u001b[39m=\u001b[39mbatch, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1121'>1122</a>\u001b[0m     step \u001b[39m=\u001b[39m step_fn(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1122'>1123</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mrecord_batch(prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_loss\u001b[39m\u001b[39m\"\u001b[39m, step[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1123'>1124</a>\u001b[0m     batch_size \u001b[39m=\u001b[39m (get_len(batch[\u001b[39m0\u001b[39m]) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m))\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1124'>1125</a>\u001b[0m                   \u001b[39melse\u001b[39;00m get_len(batch))\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1007\u001b[0m, in \u001b[0;36mNeuralNet.train_step\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=999'>1000</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1000'>1001</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1001'>1002</a>\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1002'>1003</a>\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1003'>1004</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1004'>1005</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m step[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1006'>1007</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_optimizer(step_fn)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1007'>1008</a>\u001b[0m \u001b[39mreturn\u001b[39;00m step_accumulator\u001b[39m.\u001b[39mget_step()\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:963\u001b[0m, in \u001b[0;36mNeuralNet._step_optimizer\u001b[1;34m(self, step_fn)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=960'>961</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=962'>963</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(step_fn)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=85'>86</a>\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=86'>87</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/optimizer.py?line=87'>88</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\autograd\\grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/autograd/grad_mode.py?line=27'>28</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\optim\\sgd.py:113\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=110'>111</a>\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=111'>112</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=112'>113</a>\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=114'>115</a>\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/optim/sgd.py?line=115'>116</a>\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:997\u001b[0m, in \u001b[0;36mNeuralNet.train_step.<locals>.step_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=994'>995</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_fn\u001b[39m():\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=995'>996</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_optimizer()\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=996'>997</a>\u001b[0m     step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step_single(batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=997'>998</a>\u001b[0m     step_accumulator\u001b[39m.\u001b[39mstore_step(step)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=999'>1000</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify(\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1000'>1001</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mon_grad_computed\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1001'>1002</a>\u001b[0m         named_parameters\u001b[39m=\u001b[39mTeeGenerator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_all_learnable_params()),\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1002'>1003</a>\u001b[0m         batch\u001b[39m=\u001b[39mbatch,\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1003'>1004</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:896\u001b[0m, in \u001b[0;36mNeuralNet.train_step_single\u001b[1;34m(self, batch, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=893'>894</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=894'>895</a>\u001b[0m Xi, yi \u001b[39m=\u001b[39m unpack_data(batch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=895'>896</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(Xi, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=896'>897</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loss(y_pred, yi, X\u001b[39m=\u001b[39mXi, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=897'>898</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\skorch\\net.py:1359\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[1;34m(self, x, **fit_params)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1356'>1357</a>\u001b[0m     x_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1357'>1358</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mx_dict)\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/skorch/net.py?line=1358'>1359</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\OneDrive - Aalborg Universitet\\PhD\\PhDCourses\\11. IMLA\\tsc\\src\\model.py:34\u001b[0m, in \u001b[0;36m_ConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_in,\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=33'>34</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=34'>35</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='file:///c%3A/Users/NM12LQ/OneDrive%20-%20Aalborg%20Universitet/PhD/PhDCourses/11.%20IMLA/tsc/src/model.py?line=35'>36</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\NM12LQ\\Anaconda3\\envs\\imla\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///c%3A/Users/NM12LQ/Anaconda3/envs/imla/lib/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import sleep \n",
    "\n",
    "# Import SKORCH NN classifier\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "# The Neural Net is initialized with fixed hyperparameters\n",
    "nn = NeuralNetClassifier(model._ConvNetModel(time_steps, n_classes), max_epochs=10, lr=0.01, batch_size=12, optimizer=torch.optim.SGD )# optim.RMSprop)\n",
    "X = X_train.to_numpy().astype(np.double)\n",
    "y_train= y_train.astype(np.double)\n",
    "print(X.dtype)\n",
    "print(y_train.dtype)\n",
    "nn.fit(X, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d4520545ca233a18fcbfaf6de76cf00aab1835d3dba167ce44a459e1af2c853"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('imla')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
